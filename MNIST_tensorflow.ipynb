{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP745YvP5AEt2tLLiN8n0BW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquangnguyen1992/tensorflow_colab/blob/mnist_branch/MNIST_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbsOAKgy0KEH",
        "colab_type": "text"
      },
      "source": [
        "# ***Check the Tensorflow version and load the dataset***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA1Gv85U0BEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db0ef672-caa5-46e5-cbbb-7a4677e3345e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWo_sF1s0RBP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4873fa61-5b6b-4668-9462-9fcca2af21c2"
      },
      "source": [
        "#import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Add a channels dimension\n",
        "NUMBER_OF_DATA = x_train.shape[0]\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "\n",
        "train_val_split = 0.8\n",
        "\n",
        "x_val = x_train[int(NUMBER_OF_DATA*train_val_split):,:,:,:]\n",
        "x_train = x_train[:int(NUMBER_OF_DATA*train_val_split),:,:,:]\n",
        "\n",
        "y_val = y_train[int(NUMBER_OF_DATA*train_val_split):]\n",
        "y_train = y_train[:int(NUMBER_OF_DATA*train_val_split)]\n",
        "\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "print(x_train.shape, x_val.shape, x_test.shape, y_train.shape, y_val.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 28, 28, 1) (12000, 28, 28, 1) (10000, 28, 28, 1) (48000,) (12000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYxXUT6XplRd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "e0b58e19-e558-4e29-c459-e1cf743a5d74"
      },
      "source": [
        "i = np.random.randint(0, x_train.shape[0])\n",
        "image_to_display = x_train[i]\n",
        "image_to_display = image_to_display.reshape([28, 28]).astype('float32')\n",
        "print(y_train[i])\n",
        "plt.imshow(image_to_display)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9d1cf32a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdokApGa9G2A",
        "colab_type": "text"
      },
      "source": [
        "# ***Design the NN***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8rVqeCl2Dko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "baed713a-67c4-4544-d95f-dcd417b426ae"
      },
      "source": [
        "'''W = tf.Variable(tf.zeros(shape=(28*28,10), name=\"W\"))\n",
        "b = tf.Variable(tf.ones(shape=(10)), name=\"bias\")\n",
        "\n",
        "@tf.function\n",
        "def forward(X):\n",
        "  return tf.nn.softmax(W*X+b)\n",
        "\n",
        "y_prediction = forward(image_to_display.reshape([28*28,1]))\n",
        "print(y_prediction)\n",
        "\n",
        "\n",
        "one_hot = tf.one_hot(label, depth=10)\n",
        "#cross_entropy = lambda: tf.reduce_mean(-tf.reduce_sum(one_hot*tf.math.log(y_prediction)))\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
        "#train_step = opt.minimize(cross_entropy, [one_hot, y_prediction]).numpy()\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = forward(inputs)\n",
        "    regularization_loss=tf.math.add_n(model.losses)\n",
        "    pred_loss=loss_fn(labels, predictions)\n",
        "    total_loss=pred_loss + regularization_loss\n",
        "\n",
        "  gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))'''\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.1 0.1 0.1 ... 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 ... 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 ... 0.1 0.1 0.1]\n",
            " ...\n",
            " [0.1 0.1 0.1 ... 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 ... 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 ... 0.1 0.1 0.1]], shape=(784, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-6c0de232c9d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mcross_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrain_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name)\u001b[0m\n\u001b[1;32m    334\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss)\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_clip_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    476\u001b[0m       \u001b[0;31m# Create iteration if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_all_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_create_all_weights\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_slots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/gradient_descent.py\u001b[0m in \u001b[0;36m_create_slots\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_momentum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36madd_slot\u001b[0;34m(self, var, slot_name, initializer)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mslot_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slot_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slot_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslot_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m     \u001b[0mvar_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_var_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m     \u001b[0mslot_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslot_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslot_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_var_key\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m   1243\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_distributed_container\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1245\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_graph_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1246\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_in_graph_mode'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw2wkGX-qFEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(BATCH_SIZE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_val, y_val)).shuffle(10000).batch(BATCH_SIZE)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCIW1tiIgpeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(Model):\n",
        "  def __init__(self, conv1=32, dense1=64, dropout=0.3, regular_l1=0.01, regular_l2=0.01):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = Conv2D(conv1, 3, activation='relu', \n",
        "                        kernel_regularizer=tf.keras.regularizers.l1(regular_l1),\n",
        "                        activity_regularizer=tf.keras.regularizers.l2(regular_l2))\n",
        "    self.flatten = Flatten()\n",
        "    self.Dropout = Dropout(dropout)\n",
        "    self.BatchNormalization = BatchNormalization()\n",
        "    self.d1 = Dense(dense1, activation='relu', \n",
        "                        kernel_regularizer=tf.keras.regularizers.l1(regular_l1),\n",
        "                        activity_regularizer=tf.keras.regularizers.l2(regular_l2))\n",
        "    self.d2 = Dense(10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.Dropout(x)\n",
        "    x = self.BatchNormalization(x)\n",
        "    x = self.d1(x)\n",
        "    x = self.Dropout(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel(conv1=32, dense1=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTq8-D6Z9pX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # training=True is only needed if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "    predictions = model(images, training=True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def val_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  val_loss(t_loss)\n",
        "  val_accuracy(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnpb7Bl99rcf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "10d9f1f2-679f-4e0b-f25d-a076a777a987"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  val_loss.reset_states()\n",
        "  val_accuracy.reset_states()\n",
        "  #test_loss.reset_states()\n",
        "  #test_accuracy.reset_states()\n",
        "\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for val_images, val_labels in val_ds:\n",
        "    val_step(val_images, val_labels)\n",
        "\n",
        "  #for test_images, test_labels in test_ds:\n",
        "  #  test_step(test_images, test_labels)\n",
        "\n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
        "  print(template.format(epoch + 1,\n",
        "                        train_loss.result(),\n",
        "                        train_accuracy.result() * 100,\n",
        "                        val_loss.result(),\n",
        "                        val_accuracy.result() * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer my_model_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "Epoch 1, Loss: 0.21179233491420746, Accuracy: 93.82083129882812, Val Loss: 0.08507557958364487, Val Accuracy: 97.71666717529297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA2TCkyGqPsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for test_images, test_labels in test_ds:\n",
        "  test_step(test_images, test_labels)\n",
        "\n",
        "template = 'Test Loss: {}, Test Accuracy: {}'\n",
        "print(template.format(test_loss.result(),\n",
        "                      test_accuracy.result() * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZJojnvFXafN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}